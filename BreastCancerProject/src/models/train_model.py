import sys
import os
import torch
import torch.nn as nn
import torch.optim as optim
from tqdm import tqdm

# ================= ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù…Ø³ÛŒØ± Ù‡ÙˆØ´Ù…Ù†Ø¯ (Smart Path Setup) =================
# 1. Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ÛŒ Ú©Ù‡ Ø§Ù„Ø§Ù† Ø¯Ø§Ø±Ø¯ Ø§Ø¬Ø±Ø§ Ù…ÛŒâ€ŒØ´ÙˆØ¯ (train_model.py)
current_dir = os.path.dirname(os.path.abspath(__file__))

# 2. Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ø±ÛŒØ´Ù‡ Ù¾Ø±ÙˆÚ˜Ù‡ (Ø¯Ùˆ Ù…Ø±Ø­Ù„Ù‡ Ø¹Ù‚Ø¨â€ŒÚ¯Ø±Ø¯: src/models -> src -> root)
PROJECT_ROOT = os.path.abspath(os.path.join(current_dir, '../../'))

# 3. Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø±ÛŒØ´Ù‡ Ø¨Ù‡ Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ù¾Ø§ÛŒØªÙˆÙ† (Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ…Ù¾ÙˆØ±Øª Ú©Ø±Ø¯Ù† src)
sys.path.append(PROJECT_ROOT)

# 4. Ø³Ø§Ø®Øª Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ù‚Ø·Ø¹ÛŒ Ø¨Ø±Ø§ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ CSV
TRAIN_CSV_PATH = os.path.join(PROJECT_ROOT, 'data', 'calc_train_paths.csv')
TEST_CSV_PATH = os.path.join(PROJECT_ROOT, 'data', 'calc_test_paths.csv')

# Ú†Ú© Ú©Ø±Ø¯Ù† Ø§ÛŒÙ†Ú©Ù‡ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ ÙˆØ§Ù‚Ø¹Ø§ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ù†Ø¯ (Ø¨Ø±Ø§ÛŒ Ø¯ÛŒØ¨Ø§Ú¯)
if not os.path.exists(TRAIN_CSV_PATH):
    raise FileNotFoundError(f"âŒ Error: Could not find train CSV at: {TRAIN_CSV_PATH}")

# ================= Ø§ÛŒÙ…Ù¾ÙˆØ±Øª Ù…Ø§Ú˜ÙˆÙ„â€ŒÙ‡Ø§ÛŒ Ù¾Ø±ÙˆÚ˜Ù‡ =================
from src.preprocess.dataset import build_dataloaders
from src.models.model import get_model

# ================= ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù…Ø¯Ù„ =================
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
EPOCHS = 10
LEARNING_RATE = 0.001
BATCH_SIZE = 16 

# ... (Ø¨Ù‚ÛŒÙ‡ ØªÙˆØ§Ø¨Ø¹ train_one_epoch Ùˆ evaluate Ù…Ø«Ù„ Ù‚Ø¨Ù„ Ù‡Ø³ØªÙ†Ø¯) ...

def train_one_epoch(model, loader, criterion, optimizer):
    model.train() # Ø­Ø§Ù„Øª Ø¢Ù…ÙˆØ²Ø´ (DropOut ÙØ¹Ø§Ù„ØŒ BatchNormal ÙØ¹Ø§Ù„)
    running_loss = 0.0
    correct = 0
    total = 0
    
    loop = tqdm(loader, desc="Training")
    
    for images, labels in loop:
        images, labels = images.to(DEVICE), labels.to(DEVICE).float()
        
        # 1. Forward Pass
        outputs = model(images).squeeze(1) # Ø®Ø±ÙˆØ¬ÛŒ Ù…Ø¯Ù„
        loss = criterion(outputs, labels)  # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø®Ø·Ø§
        
        # 2. Backward Pass
        optimizer.zero_grad() # ØµÙØ± Ú©Ø±Ø¯Ù† Ú¯Ø±Ø§Ø¯ÛŒØ§Ù†â€ŒÙ‡Ø§ÛŒ Ù‚Ø¨Ù„ÛŒ
        loss.backward()       # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ú¯Ø±Ø§Ø¯ÛŒØ§Ù† Ø¬Ø¯ÛŒØ¯
        optimizer.step()      # Ø¢Ù¾Ø¯ÛŒØª ÙˆØ²Ù†â€ŒÙ‡Ø§
        
        # Ø¢Ù…Ø§Ø±Ú¯ÛŒØ±ÛŒ
        running_loss += loss.item()
        preds = (torch.sigmoid(outputs) > 0.5).float() # ØªØ¨Ø¯ÛŒÙ„ Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª Ø¨Ù‡ 0 Ùˆ 1
        correct += (preds == labels).sum().item()
        total += labels.size(0)
        
        loop.set_postfix(loss=loss.item())
        
    return running_loss / len(loader), correct / total

def evaluate(model, loader, criterion):
    model.eval() # Ø­Ø§Ù„Øª Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ (Ø¨Ø¯ÙˆÙ† Ø¢Ù¾Ø¯ÛŒØª ÙˆØ²Ù†)
    running_loss = 0.0
    correct = 0
    total = 0
    
    with torch.no_grad(): # Ú¯Ø±Ø§Ø¯ÛŒØ§Ù† Ù†Ú¯ÛŒØ± (Ø±Ù… ØµØ±ÙÙ‡â€ŒØ¬ÙˆÛŒÛŒ Ù…ÛŒØ´Ù‡)
        for images, labels in loader:
            images, labels = images.to(DEVICE), labels.to(DEVICE).float()
            
            outputs = model(images).squeeze(1)
            loss = criterion(outputs, labels)
            
            running_loss += loss.item()
            preds = (torch.sigmoid(outputs) > 0.5).float()
            correct += (preds == labels).sum().item()
            total += labels.size(0)
            
    return running_loss / len(loader), correct / total

def main():
    print(f"ğŸš€ Training on {DEVICE}...")
    print(f"ğŸ“‚ Reading data from: {PROJECT_ROOT}/data")
    
    # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ù‚Ø·Ø¹ÛŒ Ú©Ù‡ Ø¨Ø§Ù„Ø§ ØªØ¹Ø±ÛŒÙ Ú©Ø±Ø¯ÛŒÙ…
    train_loader, test_loader = build_dataloaders(
        train_csv=TRAIN_CSV_PATH,  # <--- ØªØºÛŒÛŒØ± Ù…Ù‡Ù…
        test_csv=TEST_CSV_PATH,    # <--- ØªØºÛŒÛŒØ± Ù…Ù‡Ù…
        batch_size=BATCH_SIZE
    )
    
    # 2. Ø³Ø§Ø®Øª Ù…Ø¯Ù„
    model = get_model(DEVICE)
    
    # 3. ØªØ¹Ø±ÛŒÙ Loss Ùˆ Optimizer
    # BCEWithLogitsLoss Ø¨Ø±Ø§ÛŒ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ø§ÛŒÙ†Ø±ÛŒ Ø¹Ø§Ù„ÛŒÙ‡ (Ù¾Ø§ÛŒØ¯Ø§Ø±ØªØ± Ø§Ø² BCELoss)
    criterion = nn.BCEWithLogitsLoss() 
    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)
    
    best_acc = 0.0
    
    # 4. Ø­Ù„Ù‚Ù‡ Ø§ØµÙ„ÛŒ Ø¢Ù…ÙˆØ²Ø´
    for epoch in range(EPOCHS):
        print(f"\nEpoch {epoch+1}/{EPOCHS}")
        
        train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer)
        val_loss, val_acc = evaluate(model, test_loader, criterion)
        
        print(f"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}")
        print(f"Val Loss:   {val_loss:.4f} | Val Acc:   {val_acc:.4f}")
        
        # Ø°Ø®ÛŒØ±Ù‡ Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„
        if val_acc > best_acc:
            best_acc = val_acc
            torch.save(model.state_dict(), "models/best_model.pth")
            print("âœ… New Best Model Saved!")

if __name__ == "__main__":
    main()